{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f5e8cb-f365-43da-9509-d7b3d7b7f8d2",
   "metadata": {},
   "source": [
    "# Presentation:\n",
    "\n",
    "The objective of this notebook is implement the [Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347), an algorthm to solve problems of **Reinforcement Learning** focused in **Gradient Policy**, created by [OpenIA researchs](https://openai.com/index/openai-baselines-ppo/). The main ideia here is import and use the classes, and see the results.\n",
    "\n",
    "## Task:\n",
    "Many tasks can be solve by this algorithm, but for the test here, we will solve the classic [cart pole](https://gymnasium.farama.org/environments/classic_control/cart_pole/) problem, an problem with discrete space of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25587e30-2aea-42fa-b188-0c6c7ce1a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs:\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from PPOv2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd7800a-52ee-4c52-9387-3f28b81734f2",
   "metadata": {},
   "source": [
    "# Configuring the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6353fc73-19c8-4a6a-8a54-738a001bc42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.02184286,  0.01251969, -0.01805956, -0.0093485 ],\n",
       "        [-0.03887874,  0.03220272,  0.04505204,  0.0238243 ],\n",
       "        [-0.03321167, -0.03879063,  0.03040096, -0.02319589],\n",
       "        [ 0.04501588, -0.01834541, -0.03843579, -0.01910509]],\n",
       "       dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancia parâmetros utilizados na tarefa:\n",
    "args = Args(num_steps=128,\n",
    "            num_envs=4,\n",
    "            learning_rate=2.5e-4,\n",
    "            gamma=0.99,\n",
    "            gae_lambda=0.95,\n",
    "            update_epochs=4,\n",
    "            batch_size=4*128, # num_envs * num_steps\n",
    "            minibatch_size=(4*128)//4,\n",
    "            clip_coef=0.2,\n",
    "            ent_coef=0.01,\n",
    "            vf_coef=0.5,\n",
    "            max_grad_norm=0.5,\n",
    "            anneal_lr=True,\n",
    "            cuda=torch.cuda.is_available(),\n",
    "            exp_name=\"ppo_cartpole\",\n",
    "            num_iterations=1000,\n",
    "            printOn=False # Define se as métricas serão printadas durando a otimização da política \n",
    ")\n",
    "\n",
    "# Task:\n",
    "game = \"CartPole-v1\"\n",
    "\n",
    "# Instanciando Ambiente:\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(game, i) for i in range(args.num_envs)]\n",
    ");envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a8e34e-7de2-4673-8dfb-76205d2b7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_agent(agent, env_id=\"CartPole-v1\", num_episodes=1, max_steps=500, save=False, save_path=\"agent_performance.mp4\"):\n",
    "    \"\"\"\n",
    "    Visualiza o desempenho de um agente treinado em um ambiente especificado.\n",
    "\n",
    "    Args:\n",
    "        agent (PPOAgent): Agente PPO treinado.\n",
    "        env_id (str): ID do ambiente Gym. Exemplo: \"CartPole-v1\".\n",
    "        num_episodes (int): Número de episódios para visualizar.\n",
    "        max_steps (int): Número máximo de passos por episódio.\n",
    "        save (bool): Se True, salva a animação como um arquivo de vídeo.\n",
    "        save_path (str): Caminho para salvar o arquivo de vídeo.\n",
    "    \"\"\"\n",
    "    for episode in range(num_episodes):\n",
    "        # Cria o ambiente com render_mode='rgb_array'\n",
    "        env = gym.make(env_id, render_mode='rgb_array')\n",
    "        frames = []\n",
    "        \n",
    "        # Reinicia o ambiente\n",
    "        obs, info = env.reset(seed=42)\n",
    "        done = False\n",
    "        truncated = False\n",
    "        step = 0\n",
    "        \n",
    "        while not (done or truncated) and step < max_steps:\n",
    "            # Prepara a observação para o agente\n",
    "            obs_tensor = torch.Tensor(obs)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                action, _, _, _ = agent.get_action_and_value(obs_tensor)\n",
    "            \n",
    "            # Executa a ação no ambiente\n",
    "            obs, reward, done, truncated, info = env.step(action.cpu().numpy())\n",
    "            \n",
    "            # Captura o quadro atual do ambiente\n",
    "            frame = env.render()\n",
    "            frames.append(frame)\n",
    "            \n",
    "            step += 1\n",
    "        \n",
    "        env.close()\n",
    "        \n",
    "        # Cria a animação usando matplotlib\n",
    "        fig = plt.figure()\n",
    "        plt.axis('off')  # Remove os eixos para uma visualização mais limpa\n",
    "        im = plt.imshow(frames[0])  # Exibe o primeiro quadro\n",
    "        \n",
    "        def update(frame):\n",
    "            im.set_array(frame)\n",
    "            return [im]\n",
    "        \n",
    "        ani = animation.FuncAnimation(fig, update, frames=frames, interval=50, blit=True)\n",
    "        \n",
    "        # Exibe a animação\n",
    "        plt.show()\n",
    "        \n",
    "        # Opcional: Salva a animação como um arquivo de vídeo\n",
    "        if save:\n",
    "            # Requer que o ffmpeg esteja instalado no sistema\n",
    "            ani.save(save_path, writer='ffmpeg')\n",
    "            print(f\"Animação salva em {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98ca25-20a8-47fa-aed6-1264d6305f3d",
   "metadata": {},
   "source": [
    "# Policy Optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e43afc-a7d2-4c22-bc10-8f887bd211c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intancia o agent:\n",
    "agent = PPOAgent(envs.single_observation_space, envs.single_action_space)\n",
    "\n",
    "# Intancia o Treinamento:\n",
    "trainer = PPOTrainer(agent, envs, args)\n",
    "\n",
    "# Traina Modelo:\n",
    "trainer.train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17519a10-b3dc-48ab-bb42-127d82494a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['episodic_return', 'episodic_length', 'episodic_time', 'value_loss', 'policy_loss', 'entropy_loss', 'old_approx_kl', 'approx_kl', 'clipfrac', 'explained_variance', 'learning_rate', 'SPS'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acesso às métricas\n",
    "metrics = trainer.get_metrics()\n",
    "\n",
    "# Elementos Avaliados:\n",
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb9b2b-088e-4c98-a662-d454f7c76026",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6c0f87-28ba-4455-ab18-a5038889e67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animação salva em agent_performance(CartPole-v1).gif\n"
     ]
    }
   ],
   "source": [
    "# Visualização de performance:\n",
    "visualize_agent(agent, env_id=game, num_episodes=1, max_steps=500, save=True, save_path=f\"agent_performance({game}).gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
