# Content:

## PPO.py:
Code related to the classes for the PPO implementation, a module that can be used as a library in a script.

## PPO_Implementation.ipynb:
PPO implementation using the structure of a notebook. The interesting part here is that the function to build the GIF showing the policy learned by the agent is included in this code.

## main.py:
Another implementation of PPO, but in script format.

## agent_performance.gif:
A GIF created by the visualization function found in the notebook, showing the policy learned by the agent. It provides a more intuitive view of the final result, beyond the mathematical metrics (which are also included in the code).
